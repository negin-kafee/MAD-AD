
# âœ¨ MAD-AD âœ¨
**A PyTorch Implementation for Unsupervised Brain Anomaly Detection**

This repository hosts the official PyTorch implementation for our paper accepted in IPMI2025:  
["MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection"](https://arxiv.org/abs/2502.16943).

---

## ğŸ¨ Approach

![MAD-AD Method](./assets/method.png)

---

## âš™ï¸ Setup

### ğŸ› ï¸ Environment

Our experiments run on **Python 3.11**. Install all the required packages by executing:

```bash
pip3 install -r requirements.txt
```

### ğŸ“ Datasets

Prepare your data as follows:

1. **Data Registration & Preprocessing:**  
   - Register with MNI_152_1mm.
   - Preprocess, normalize, and extract axial slices.

2. **Dataset Organization:**  
   - Ensure **training** and **validation** sets contain only normal, healthy data.
   - **Test** set should include abnormal slices.
   - Organize your files using this structure:

   ```
   â”œâ”€â”€ Data
       â”œâ”€â”€ train
       â”‚   â”œâ”€â”€ {train_image_id}-slice_{slice_idx}-{modality}.png
       â”‚   â”œâ”€â”€ {train_image_id}-slice_{slice_idx}-brainmask.png
       â”‚   â””â”€â”€ ...
       â”œâ”€â”€ val
       â”‚   â”œâ”€â”€ {val_image_id}-slice_{slice_idx}-{modality}.png
       â”‚   â”œâ”€â”€ {val_image_id}-slice_{slice_idx}-brainmask.png
       â”‚   â””â”€â”€ ...
       â””â”€â”€ test
           â”œâ”€â”€ {test_image_id}-slice_{slice_idx}-{modality}.png
           â”œâ”€â”€ {test_image_id}-slice_{slice_idx}-brainmask.png
           â”œâ”€â”€ {test_image_id}-slice_{slice_idx}-segmentation.png
           â””â”€â”€ ...
   ```

---

## ğŸ”§ Pretrained Weights & VAE Fine-Tuning

### Pretrained VAE Models

To jumpstart your experiments, we provide pretrained weights adapted for 1-channel medical brain images. These models are available on [HuggingFace](https://huggingface.co/farzadbz/Medical-VAE).

### Train & Fine-Tune VAE

If you prefer to train your own VAE from scratch, please refer to the [LDM-VAE repository](https://github.com/CompVis/latent-diffusion?tab=readme-ov-file#training-autoencoder-models) for detailed instructions.

---

## ğŸš„ Training MAD-AD

To train MAD-AD, run the following command. This configuration leverages a UNet_L model with data augmentation and integrates the pretrained VAE:

```bash
torchrun train_MAD_AD.py \
            --modality T1 \
            --model UNet_L \
            --mask-ratio 0.75 \
            --image-size 256 \
            --augmentation True \
            --data_root ./data/ \
            --ckpt-every 20 
```


## ğŸš¦ Evaluating MAD-AD
To evaluate MAD-AD model, use the following command.
Note: evaluate-MAD-AD.py loads its configuration and arguments from the YAML file located in the parent directory of the given model checkpoint path. The script computes four evaluation metrics and saves per-image visualizations in the parent folder of the model path:

```bash
torchrun evaluate-MAD-AD.py \
            --data-root ./data/ \
            --model-path ./MAD-AD_T2_UNet_L/001-UNet_L/checkpoints/last.pt
```

---
## ğŸ“¸ Sample Results


![Sample Results](./assets/results.png)

---

## ğŸ“š Citation & Reference

If you find MAD-AD useful in your research, please cite our work:

```bibtex
@inproceedings{beizaee2025mad,
  title={MAD-AD: Masked Diffusion for Unsupervised Brain Anomaly Detection},
  author={Beizaee, Farzad and Lodygensky, Gregory and Desrosiers, Christian and Dolz, Jose},
  booktitle={International Conference on Information Processing in Medical Imaging},
  pages={139--153},
  year={2025},
  organization={Springer}
}
```

